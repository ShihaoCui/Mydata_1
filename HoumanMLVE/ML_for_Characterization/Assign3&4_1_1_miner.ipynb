{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShihaoCui/Mydata_1/blob/main/Assign3%264_1_1_miner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hEPU9UmFpE0"
      },
      "source": [
        "### A typical AlexNet architecture is given below:\n",
        "\n",
        "Convolutional layer: 96 11 * 11 filters with a stride of 4\n",
        "\n",
        "Max pooling: 3 *3 max pooling with a stride of 2\n",
        "\n",
        "Convolutional layer: 256 5*5 filters with a stride of 2\n",
        "\n",
        "Max pooling: 3 *3 max pooling with a stride of 2\n",
        "\n",
        "Convolutional layer: 384 3 * 3 filters with a stride of 1\n",
        "\n",
        "Convolutional layer: 384 3 * 3 filters with a stride of 1\n",
        "\n",
        "Convolutional layer: 256 3 * 3 filters with a stride of 1\n",
        "\n",
        "Max pooling: 3* 3 max pooling with a stride of 2\n",
        "\n",
        "Fully Connected Layer: 4096 neurons\n",
        "\n",
        "Fully Connected Layer: 4096 neurons\n",
        "\n",
        "Fully Connected Layer: **1000** neurons\n",
        "\n",
        "As a first observation, please note the last fully connected layer consists of 1000 neurons, because AlexNet presented results on a 1000 class problem. Since you are dealing with a 10-class problem, obviously the last layer would consist of 10 neurons. Moreover, for a 10-class problem, it is possible that the three convolutional layers (before the FC layers) might be an overkill. So I'll be open to accepting implementations with a subset of layers in the typical architecture.                                        "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdQITKt22i7r"
      },
      "source": [
        "# ## switch to GPU\n",
        "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "# !apt-get update -qq 2>&1 > /dev/null\n",
        "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# creds = GoogleCredentials.get_application_default()\n",
        "# import getpass\n",
        "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "# vcode = getpass.getpass()\n",
        "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsX8b4d3EghZ"
      },
      "source": [
        "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# from tensorflow.python.client import device_lib\n",
        "# print(device_lib.list_local_devices())\n",
        "# from tensorflow.python.client import device_lib\n",
        "# print(device_lib.list_local_devices())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvgmvWXcvotG"
      },
      "source": [
        "#### (a) Using your favorite framework implement an Alex(Like)Net for 10-class classification, explaining your choice of layers. Do not use batch normalization. You may use drop-out for the fully connected layers. All activation functions would be ReLU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxSdXtauFgP6"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten,BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D,Convolution2D\n",
        "# from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/ShihaoCui/MyData_1.git\n",
        "\n",
        "# import scipy.io as scio\n",
        "# dataFile = './MyData_1/Coal mining pi/Image processed/all figures/XX.mat'\n",
        "# data = scio.loadmat(dataFile)\n",
        "\n",
        "# Data = data['XX']\n",
        "# Data.shape\n",
        "\n",
        "# train_X=np.array(Data,dtype=\"float16\")\n",
        "# train_X  = train_X.reshape(-1,930,1050,3)\n",
        "# train_X.shape\n",
        "\n",
        "# train_Y = np.array([0,0,0,0,0,0,0,0,0,0,#\n",
        "#                     1,1,1,1,1,1,1,\n",
        "#                     2,2,2,2,2,2,2,2,2,2,\n",
        "#                     3,3,3,3,3,3,3,3,3,3,3],dtype=\"int\")\n",
        "# train_Y = train_Y.reshape(-1)\n",
        "# train_Y.shape\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X = train_X\n",
        "# Y1 = train_Y\n",
        "# x_train, x_test, y_train, y_test = train_test_split(X, Y1, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "MlwVYdt49LtK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ShihaoCui/MyData_1.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJPQeMOG5vZ7",
        "outputId": "349cbe9c-f1d6-43b1-adf9-b08970ec2fb2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MyData_1'...\n",
            "remote: Enumerating objects: 703, done.\u001b[K\n",
            "remote: Counting objects: 100% (377/377), done.\u001b[K\n",
            "remote: Compressing objects: 100% (291/291), done.\u001b[K\n",
            "remote: Total 703 (delta 178), reused 278 (delta 80), pack-reused 326\u001b[K\n",
            "Receiving objects: 100% (703/703), 359.25 MiB | 16.01 MiB/s, done.\n",
            "Resolving deltas: 100% (257/257), done.\n",
            "Updating files: 100% (324/324), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as scio\n",
        "dataFile = './MyData_1/Coal mining pi/Image processed/all figures/XX.mat'\n",
        "data = scio.loadmat(dataFile)"
      ],
      "metadata": {
        "id": "3omUNLu-5zJg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data = data['XX']\n",
        "Data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzISray651qL",
        "outputId": "64bf3abc-1260-4f35-f3e0-1c0a6adbd3ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(930, 1050, 3, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X=np.array(Data,dtype=\"float16\")\n",
        "train_X  = train_X.reshape(-1,930,1050,3)\n",
        "train_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBgYk4FB6Dmw",
        "outputId": "a32b5025-9dcf-40ea-c245-a39f666e0819"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 930, 1050, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_Y = np.array([0,0,0,0,0,0,0,0,0,0,# 10\n",
        "                    1,1,1,1,1,1,1, # 7\n",
        "                    2,2,2,2,2,2,2,2,2,2,# 10\n",
        "                    3,3,3,3,3,3,3,3,3,3,3],# 11\n",
        "                   dtype=\"int\")\n",
        "train_Y = train_Y.reshape(-1)\n",
        "train_Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbgLJdqx6NsO",
        "outputId": "98e01c4b-0a46-42f3-9b80-9cd1d3025180"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_Y = np.array([0,0,0,#\n",
        "#                     1,1,1,1,1,1,1,\n",
        "#                     2,2,2,2,2,2,2,2,\n",
        "#                     3,3,3,3,3,3,3,3,3,3,3],dtype=\"int\")\n",
        "# train_Y = train_Y.reshape(-1)\n",
        "# train_Y.shape"
      ],
      "metadata": {
        "id": "vdp23oFbDeyV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = train_X\n",
        "Y1 = train_Y\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y1, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5zLF-sgY6Rxh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC2XZzLrFvjG"
      },
      "source": [
        "# load the data: train and test\n",
        "# (x_train,y_train),(x_test,y_test) = cifar10.load_data()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1JY9WsZc6KtT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w6PxP4dFzvm",
        "outputId": "ccae43de-d795-49d2-e698-0abe34e3f3ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# data processing\n",
        "from keras.utils import to_categorical\n",
        "x_train = x_train.reshape(-1,3,930,1050)/255\n",
        "x_test = x_test.reshape(-1,3,930,1050)/255\n",
        "y_train = keras.utils.to_categorical(y_train,num_classes = 4)\n",
        "y_test =keras.utils.to_categorical(y_test, num_classes=4)\n",
        "x_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 3, 930, 1050)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrTDefLY3nbL",
        "outputId": "ed0ae5b8-9598-49aa-f272-41a5b01a4754"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1oN7VvF3lM"
      },
      "source": [
        "model  = Sequential()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsRT9T18F7Kz",
        "outputId": "a86a4914-3e96-4646-f50f-ffdc13c112c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# # Convolutional layer: 96 11*11 lters with a stride of 4 # 1\n",
        "# model.add(Conv2D(64,(3,3),strides=4,padding='same'))\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "# # Max pooling: 3*3 max pooling with a stride of 2 # 2\n",
        "# model.add(MaxPooling2D(\n",
        "#     pool_size=(3,3),\n",
        "#     strides=2,\n",
        "#     padding='same',    # Padding method\n",
        "#     data_format='channels_first',\n",
        "# ))\n",
        "# # model.summary()\n",
        "\n",
        "# Convolutional layer: 96 11*11 lters with a stride of 4 # 1\n",
        "model.add(Convolution2D(\n",
        "    batch_input_shape=(None, 3, 930, 1050),\n",
        "    kernel_size = (93,105),\n",
        "    filters=96,\n",
        "   # kernel_size=5,\n",
        "    strides=4,\n",
        "    padding='same',      # Padding method\n",
        "    data_format='channels_first',\n",
        "))\n",
        "model.add(BatchNormalization()) # Batchnormalization\n",
        "\n",
        "\n",
        "# Max pooling: 3*3 max pooling with a stride of 2 # 2\n",
        "model.add(MaxPooling2D(\n",
        "    pool_size=(3,3),\n",
        "    strides=2,\n",
        "    padding='same',    # Padding method\n",
        "    data_format='channels_first',\n",
        "))\n",
        "model.add(Activation('relu'))\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 96, 233, 263)      2812416   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 96, 233, 263)      1052      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 96, 117, 132)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " activation (Activation)     (None, 96, 117, 132)      0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2813468 (10.73 MB)\n",
            "Trainable params: 2812942 (10.73 MB)\n",
            "Non-trainable params: 526 (2.05 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGvR5NKTF9yy"
      },
      "source": [
        "# Convolutional layer: 256 5*5 lters with a stride of 2 # 3\n",
        "# Max pooling: 3*3 max pooling with a stride of 2 # 4\n",
        "model.add(Convolution2D(256,kernel_size = (11,11), strides=2, padding='same', data_format='channels_first'))\n",
        "model.add(MaxPooling2D(pool_size= (3,3), padding = 'same',strides=2,data_format='channels_first'))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHb6YUriIFdm",
        "outputId": "fb1f2366-dafc-409f-de1f-15fdd1425ff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Convolutional layer: 384 3*3 lters with a stride of 1 # 5\n",
        "model.add(Convolution2D(384,kernel_size = (3,3), strides=1, padding='same', data_format='channels_first'))\n",
        "model.add(Activation('relu'))\n",
        "# Convolutional layer: 384 3*3 lters with a stride of 1 # 6\n",
        "model.add(Convolution2D(384,kernel_size = (3,3), strides=1, padding='same', data_format='channels_first'))\n",
        "model.add(Activation('relu'))\n",
        "# Convolutional layer: 256 3 *3 lters with a stride of 1 # 7\n",
        "model.add(Convolution2D(256,kernel_size = (3,3),  strides=1, padding='same', data_format='channels_first'))\n",
        "# Max pooling: 3 *3 max pooling with a stride of 2 # 8\n",
        "model.add(MaxPooling2D(pool_size= (3,3), padding = 'same',strides=2,data_format='channels_first'))\n",
        "model.add(Activation('relu'))\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 96, 233, 263)      2812416   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 96, 233, 263)      1052      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 96, 117, 132)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " activation (Activation)     (None, 96, 117, 132)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 256, 59, 66)       2973952   \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 256, 30, 33)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 256, 30, 33)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 384, 30, 33)       885120    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 384, 30, 33)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 384, 30, 33)       1327488   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 384, 30, 33)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 256, 30, 33)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 256, 15, 17)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256, 15, 17)       0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8885020 (33.89 MB)\n",
            "Trainable params: 8884494 (33.89 MB)\n",
            "Non-trainable params: 526 (2.05 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ8MoDkoIP1s",
        "outputId": "bc3e0d37-77e4-424e-8fbc-fcb442bc3525",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.add(Flatten())\n",
        "# Fully Connected Layer: 4096 neurons # 9\n",
        "model.add(Dense(4069))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Activation('relu'))\n",
        "# Fully Connected Layer: 4096 neurons # 10\n",
        "model.add(Dense(4069))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Activation('relu'))\n",
        "# Fully Connected Layer: 10* neurons # 11\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax')) # for classification\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 96, 233, 263)      2812416   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 96, 233, 263)      1052      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 96, 117, 132)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " activation (Activation)     (None, 96, 117, 132)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 256, 59, 66)       2973952   \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 256, 30, 33)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 256, 30, 33)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 384, 30, 33)       885120    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 384, 30, 33)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 384, 30, 33)       1327488   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 384, 30, 33)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 256, 30, 33)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 256, 15, 17)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256, 15, 17)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65280)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4069)              265628389 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4069)              0         \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4069)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4069)              16560830  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4069)              0         \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4069)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 16280     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 291090519 (1.08 GB)\n",
            "Trainable params: 291089993 (1.08 GB)\n",
            "Non-trainable params: 526 (2.05 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ompQlYy2vze1"
      },
      "source": [
        "#### (b) (50 Points) Train the above network on CIFAR-10 (without data augmentation) using RMSProp gradient update (you are not required to implement it, you can use your framework's implementation). Along side, you will have to make appropriate choices for the learning rate, batch size, number of training epochs. Report your results on the test set in the form of confusion matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFqPPq1HIUFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f483a2f-7fb9-45df-9948-8642f08d22b3"
      },
      "source": [
        "opt = Adam(lr = 1e-4)\n",
        "\n",
        "# opt= optimizers.RMSprop(lr=0.0001)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMOMwaoaIVKK"
      },
      "source": [
        "model.compile(optimizer = opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGpJDNVfIXt5",
        "outputId": "3ebb9651-8d7d-446f-b2b6-a722976bc8cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training\n",
        "history = model.fit(x_train,y_train,epochs = 250, batch_size = 30)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "1/1 [==============================] - 93s 93s/step - loss: 1.4233 - accuracy: 0.3000\n",
            "Epoch 2/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1028.5057 - accuracy: 0.3000\n",
            "Epoch 3/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 21.8600 - accuracy: 0.2333\n",
            "Epoch 4/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 2.8904 - accuracy: 0.3333\n",
            "Epoch 5/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.4865 - accuracy: 0.2667\n",
            "Epoch 6/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3810 - accuracy: 0.2333\n",
            "Epoch 7/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3681 - accuracy: 0.2333\n",
            "Epoch 8/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3837 - accuracy: 0.2333\n",
            "Epoch 9/250\n",
            "1/1 [==============================] - 1s 620ms/step - loss: 1.3658 - accuracy: 0.3000\n",
            "Epoch 10/250\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 1.3688 - accuracy: 0.3333\n",
            "Epoch 11/250\n",
            "1/1 [==============================] - 1s 605ms/step - loss: 1.3684 - accuracy: 0.1667\n",
            "Epoch 12/250\n",
            "1/1 [==============================] - 1s 603ms/step - loss: 1.3737 - accuracy: 0.2333\n",
            "Epoch 13/250\n",
            "1/1 [==============================] - 1s 604ms/step - loss: 1.3880 - accuracy: 0.3000\n",
            "Epoch 14/250\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 1.3629 - accuracy: 0.3000\n",
            "Epoch 15/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3632 - accuracy: 0.4000\n",
            "Epoch 16/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3665 - accuracy: 0.2333\n",
            "Epoch 17/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3628 - accuracy: 0.3333\n",
            "Epoch 18/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3601 - accuracy: 0.3333\n",
            "Epoch 19/250\n",
            "1/1 [==============================] - 1s 627ms/step - loss: 1.4815 - accuracy: 0.2333\n",
            "Epoch 20/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3837 - accuracy: 0.3000\n",
            "Epoch 21/250\n",
            "1/1 [==============================] - 1s 617ms/step - loss: 1.3748 - accuracy: 0.2333\n",
            "Epoch 22/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3707 - accuracy: 0.2333\n",
            "Epoch 23/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3617 - accuracy: 0.3333\n",
            "Epoch 24/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3357 - accuracy: 0.4333\n",
            "Epoch 25/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3445 - accuracy: 0.2667\n",
            "Epoch 26/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3379 - accuracy: 0.3667\n",
            "Epoch 27/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3473 - accuracy: 0.2333\n",
            "Epoch 28/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3363 - accuracy: 0.2667\n",
            "Epoch 29/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3339 - accuracy: 0.3667\n",
            "Epoch 30/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3194 - accuracy: 0.3333\n",
            "Epoch 31/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3356 - accuracy: 0.3333\n",
            "Epoch 32/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3265 - accuracy: 0.3667\n",
            "Epoch 33/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3227 - accuracy: 0.4333\n",
            "Epoch 34/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3396 - accuracy: 0.3667\n",
            "Epoch 35/250\n",
            "1/1 [==============================] - 1s 609ms/step - loss: 1.3147 - accuracy: 0.3667\n",
            "Epoch 36/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3490 - accuracy: 0.2667\n",
            "Epoch 37/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3375 - accuracy: 0.3667\n",
            "Epoch 38/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3647 - accuracy: 0.3000\n",
            "Epoch 39/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2950 - accuracy: 0.4000\n",
            "Epoch 40/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3447 - accuracy: 0.3000\n",
            "Epoch 41/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3186 - accuracy: 0.4000\n",
            "Epoch 42/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3488 - accuracy: 0.3333\n",
            "Epoch 43/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3425 - accuracy: 0.3667\n",
            "Epoch 44/250\n",
            "1/1 [==============================] - 1s 619ms/step - loss: 1.2923 - accuracy: 0.3667\n",
            "Epoch 45/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3647 - accuracy: 0.3667\n",
            "Epoch 46/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2869 - accuracy: 0.4000\n",
            "Epoch 47/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3121 - accuracy: 0.4333\n",
            "Epoch 48/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3180 - accuracy: 0.3667\n",
            "Epoch 49/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2590 - accuracy: 0.4333\n",
            "Epoch 50/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3007 - accuracy: 0.2333\n",
            "Epoch 51/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3110 - accuracy: 0.2333\n",
            "Epoch 52/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.2494 - accuracy: 0.4333\n",
            "Epoch 53/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2969 - accuracy: 0.4000\n",
            "Epoch 54/250\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 1.2713 - accuracy: 0.3667\n",
            "Epoch 55/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2787 - accuracy: 0.4000\n",
            "Epoch 56/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2879 - accuracy: 0.4000\n",
            "Epoch 57/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2623 - accuracy: 0.4000\n",
            "Epoch 58/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2663 - accuracy: 0.4000\n",
            "Epoch 59/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.2353 - accuracy: 0.4333\n",
            "Epoch 60/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2322 - accuracy: 0.2000\n",
            "Epoch 61/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2707 - accuracy: 0.4000\n",
            "Epoch 62/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.2469 - accuracy: 0.4333\n",
            "Epoch 63/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2325 - accuracy: 0.4000\n",
            "Epoch 64/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2334 - accuracy: 0.4000\n",
            "Epoch 65/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2145 - accuracy: 0.4000\n",
            "Epoch 66/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.4069 - accuracy: 0.2333\n",
            "Epoch 67/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3352 - accuracy: 0.3667\n",
            "Epoch 68/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.4037 - accuracy: 0.3000\n",
            "Epoch 69/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.4055 - accuracy: 0.3000\n",
            "Epoch 70/250\n",
            "1/1 [==============================] - 1s 625ms/step - loss: 1.4082 - accuracy: 0.3000\n",
            "Epoch 71/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3766 - accuracy: 0.3000\n",
            "Epoch 72/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3412 - accuracy: 0.3000\n",
            "Epoch 73/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2975 - accuracy: 0.4000\n",
            "Epoch 74/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3496 - accuracy: 0.2333\n",
            "Epoch 75/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3110 - accuracy: 0.2333\n",
            "Epoch 76/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.2909 - accuracy: 0.4000\n",
            "Epoch 77/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3139 - accuracy: 0.4000\n",
            "Epoch 78/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3205 - accuracy: 0.3667\n",
            "Epoch 79/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3004 - accuracy: 0.3667\n",
            "Epoch 80/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2908 - accuracy: 0.3333\n",
            "Epoch 81/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2853 - accuracy: 0.3000\n",
            "Epoch 82/250\n",
            "1/1 [==============================] - 1s 597ms/step - loss: 1.2719 - accuracy: 0.3000\n",
            "Epoch 83/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2645 - accuracy: 0.4333\n",
            "Epoch 84/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2672 - accuracy: 0.4000\n",
            "Epoch 85/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2454 - accuracy: 0.4000\n",
            "Epoch 86/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2585 - accuracy: 0.4667\n",
            "Epoch 87/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2551 - accuracy: 0.4000\n",
            "Epoch 88/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2322 - accuracy: 0.4000\n",
            "Epoch 89/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2396 - accuracy: 0.4000\n",
            "Epoch 90/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2251 - accuracy: 0.4000\n",
            "Epoch 91/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2262 - accuracy: 0.4000\n",
            "Epoch 92/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.2068 - accuracy: 0.4000\n",
            "Epoch 93/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2147 - accuracy: 0.4000\n",
            "Epoch 94/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.1951 - accuracy: 0.4000\n",
            "Epoch 95/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.1959 - accuracy: 0.4667\n",
            "Epoch 96/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.2110 - accuracy: 0.3667\n",
            "Epoch 97/250\n",
            "1/1 [==============================] - 1s 609ms/step - loss: 1.1891 - accuracy: 0.4333\n",
            "Epoch 98/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 6.3177 - accuracy: 0.2667\n",
            "Epoch 99/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.8569 - accuracy: 0.2000\n",
            "Epoch 100/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3434 - accuracy: 0.4000\n",
            "Epoch 101/250\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 1.6425 - accuracy: 0.3000\n",
            "Epoch 102/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.2369 - accuracy: 0.3667\n",
            "Epoch 103/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.2761 - accuracy: 0.2000\n",
            "Epoch 104/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2948 - accuracy: 0.4000\n",
            "Epoch 105/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3652 - accuracy: 0.3667\n",
            "Epoch 106/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3514 - accuracy: 0.3333\n",
            "Epoch 107/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3189 - accuracy: 0.2333\n",
            "Epoch 108/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3525 - accuracy: 0.3000\n",
            "Epoch 109/250\n",
            "1/1 [==============================] - 1s 621ms/step - loss: 1.2893 - accuracy: 0.2333\n",
            "Epoch 110/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.2690 - accuracy: 0.4000\n",
            "Epoch 111/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 2.0756 - accuracy: 0.2000\n",
            "Epoch 112/250\n",
            "1/1 [==============================] - 1s 626ms/step - loss: 1.4790 - accuracy: 0.3000\n",
            "Epoch 113/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.5104 - accuracy: 0.3000\n",
            "Epoch 114/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.5117 - accuracy: 0.3000\n",
            "Epoch 115/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.4873 - accuracy: 0.3000\n",
            "Epoch 116/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.4762 - accuracy: 0.3000\n",
            "Epoch 117/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.4543 - accuracy: 0.3000\n",
            "Epoch 118/250\n",
            "1/1 [==============================] - 1s 618ms/step - loss: 1.4345 - accuracy: 0.3000\n",
            "Epoch 119/250\n",
            "1/1 [==============================] - 1s 605ms/step - loss: 1.4247 - accuracy: 0.3000\n",
            "Epoch 120/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.4189 - accuracy: 0.3000\n",
            "Epoch 121/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.4118 - accuracy: 0.3000\n",
            "Epoch 122/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.4032 - accuracy: 0.3000\n",
            "Epoch 123/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3913 - accuracy: 0.3000\n",
            "Epoch 124/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3853 - accuracy: 0.3000\n",
            "Epoch 125/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3858 - accuracy: 0.3000\n",
            "Epoch 126/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3773 - accuracy: 0.3000\n",
            "Epoch 127/250\n",
            "1/1 [==============================] - 1s 615ms/step - loss: 1.3855 - accuracy: 0.3000\n",
            "Epoch 128/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3759 - accuracy: 0.2667\n",
            "Epoch 129/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3767 - accuracy: 0.3333\n",
            "Epoch 130/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3832 - accuracy: 0.3000\n",
            "Epoch 131/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3804 - accuracy: 0.3000\n",
            "Epoch 132/250\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 1.3850 - accuracy: 0.3333\n",
            "Epoch 133/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3725 - accuracy: 0.2667\n",
            "Epoch 134/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3798 - accuracy: 0.3333\n",
            "Epoch 135/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3772 - accuracy: 0.2667\n",
            "Epoch 136/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3800 - accuracy: 0.2333\n",
            "Epoch 137/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3792 - accuracy: 0.3000\n",
            "Epoch 138/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3755 - accuracy: 0.2667\n",
            "Epoch 139/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3758 - accuracy: 0.3667\n",
            "Epoch 140/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3763 - accuracy: 0.3000\n",
            "Epoch 141/250\n",
            "1/1 [==============================] - 1s 611ms/step - loss: 1.3726 - accuracy: 0.3000\n",
            "Epoch 142/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3763 - accuracy: 0.3000\n",
            "Epoch 143/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3802 - accuracy: 0.3000\n",
            "Epoch 144/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3751 - accuracy: 0.3000\n",
            "Epoch 145/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3786 - accuracy: 0.3000\n",
            "Epoch 146/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3712 - accuracy: 0.3000\n",
            "Epoch 147/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3757 - accuracy: 0.3000\n",
            "Epoch 148/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3698 - accuracy: 0.3000\n",
            "Epoch 149/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3778 - accuracy: 0.3000\n",
            "Epoch 150/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3792 - accuracy: 0.3000\n",
            "Epoch 151/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3751 - accuracy: 0.3000\n",
            "Epoch 152/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3776 - accuracy: 0.3000\n",
            "Epoch 153/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3788 - accuracy: 0.3000\n",
            "Epoch 154/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3787 - accuracy: 0.3000\n",
            "Epoch 155/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3778 - accuracy: 0.3000\n",
            "Epoch 156/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3674 - accuracy: 0.3000\n",
            "Epoch 157/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3682 - accuracy: 0.3000\n",
            "Epoch 158/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3751 - accuracy: 0.3000\n",
            "Epoch 159/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3747 - accuracy: 0.3000\n",
            "Epoch 160/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3769 - accuracy: 0.3000\n",
            "Epoch 161/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3788 - accuracy: 0.3000\n",
            "Epoch 162/250\n",
            "1/1 [==============================] - 1s 618ms/step - loss: 1.3759 - accuracy: 0.3000\n",
            "Epoch 163/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3788 - accuracy: 0.2667\n",
            "Epoch 164/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3746 - accuracy: 0.3000\n",
            "Epoch 165/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3793 - accuracy: 0.3000\n",
            "Epoch 166/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3842 - accuracy: 0.3000\n",
            "Epoch 167/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3787 - accuracy: 0.3000\n",
            "Epoch 168/250\n",
            "1/1 [==============================] - 1s 626ms/step - loss: 1.3772 - accuracy: 0.3000\n",
            "Epoch 169/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3722 - accuracy: 0.3000\n",
            "Epoch 170/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3759 - accuracy: 0.3000\n",
            "Epoch 171/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3807 - accuracy: 0.3000\n",
            "Epoch 172/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3677 - accuracy: 0.3000\n",
            "Epoch 173/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3849 - accuracy: 0.3000\n",
            "Epoch 174/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3782 - accuracy: 0.3000\n",
            "Epoch 175/250\n",
            "1/1 [==============================] - 1s 610ms/step - loss: 1.3805 - accuracy: 0.3000\n",
            "Epoch 176/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3783 - accuracy: 0.3000\n",
            "Epoch 177/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3751 - accuracy: 0.3000\n",
            "Epoch 178/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3730 - accuracy: 0.3000\n",
            "Epoch 179/250\n",
            "1/1 [==============================] - 1s 619ms/step - loss: 1.3740 - accuracy: 0.3000\n",
            "Epoch 180/250\n",
            "1/1 [==============================] - 1s 621ms/step - loss: 1.3720 - accuracy: 0.3000\n",
            "Epoch 181/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3800 - accuracy: 0.3000\n",
            "Epoch 182/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3671 - accuracy: 0.3000\n",
            "Epoch 183/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3759 - accuracy: 0.3000\n",
            "Epoch 184/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3776 - accuracy: 0.3000\n",
            "Epoch 185/250\n",
            "1/1 [==============================] - 1s 608ms/step - loss: 1.3756 - accuracy: 0.3000\n",
            "Epoch 186/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3760 - accuracy: 0.3000\n",
            "Epoch 187/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3753 - accuracy: 0.3000\n",
            "Epoch 188/250\n",
            "1/1 [==============================] - 1s 616ms/step - loss: 1.3779 - accuracy: 0.3000\n",
            "Epoch 189/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3750 - accuracy: 0.3000\n",
            "Epoch 190/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3828 - accuracy: 0.3000\n",
            "Epoch 191/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3807 - accuracy: 0.3000\n",
            "Epoch 192/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3749 - accuracy: 0.3000\n",
            "Epoch 193/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3750 - accuracy: 0.3000\n",
            "Epoch 194/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3782 - accuracy: 0.3000\n",
            "Epoch 195/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3687 - accuracy: 0.3000\n",
            "Epoch 196/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3749 - accuracy: 0.3000\n",
            "Epoch 197/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3774 - accuracy: 0.3000\n",
            "Epoch 198/250\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 1.3786 - accuracy: 0.3000\n",
            "Epoch 199/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3728 - accuracy: 0.3000\n",
            "Epoch 200/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3810 - accuracy: 0.3000\n",
            "Epoch 201/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3721 - accuracy: 0.3000\n",
            "Epoch 202/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3807 - accuracy: 0.3000\n",
            "Epoch 203/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3734 - accuracy: 0.3000\n",
            "Epoch 204/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3759 - accuracy: 0.3000\n",
            "Epoch 205/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3796 - accuracy: 0.3000\n",
            "Epoch 206/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3709 - accuracy: 0.3000\n",
            "Epoch 207/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3757 - accuracy: 0.3000\n",
            "Epoch 208/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3783 - accuracy: 0.3000\n",
            "Epoch 209/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3712 - accuracy: 0.3000\n",
            "Epoch 210/250\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 1.3767 - accuracy: 0.3000\n",
            "Epoch 211/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3735 - accuracy: 0.3000\n",
            "Epoch 212/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3746 - accuracy: 0.3000\n",
            "Epoch 213/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3681 - accuracy: 0.3000\n",
            "Epoch 214/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3789 - accuracy: 0.3000\n",
            "Epoch 215/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3693 - accuracy: 0.3000\n",
            "Epoch 216/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3710 - accuracy: 0.3000\n",
            "Epoch 217/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3699 - accuracy: 0.3000\n",
            "Epoch 218/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3770 - accuracy: 0.3000\n",
            "Epoch 219/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3771 - accuracy: 0.3000\n",
            "Epoch 220/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3731 - accuracy: 0.3000\n",
            "Epoch 221/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3761 - accuracy: 0.3000\n",
            "Epoch 222/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3721 - accuracy: 0.3000\n",
            "Epoch 223/250\n",
            "1/1 [==============================] - 1s 615ms/step - loss: 1.3772 - accuracy: 0.3000\n",
            "Epoch 224/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3771 - accuracy: 0.3000\n",
            "Epoch 225/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3797 - accuracy: 0.3000\n",
            "Epoch 226/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3740 - accuracy: 0.3000\n",
            "Epoch 227/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3786 - accuracy: 0.3000\n",
            "Epoch 228/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3693 - accuracy: 0.3000\n",
            "Epoch 229/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3885 - accuracy: 0.3000\n",
            "Epoch 230/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3818 - accuracy: 0.3000\n",
            "Epoch 231/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3804 - accuracy: 0.3000\n",
            "Epoch 232/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3701 - accuracy: 0.3000\n",
            "Epoch 233/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3797 - accuracy: 0.3000\n",
            "Epoch 234/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3789 - accuracy: 0.3000\n",
            "Epoch 235/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3635 - accuracy: 0.3000\n",
            "Epoch 236/250\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 1.3821 - accuracy: 0.3000\n",
            "Epoch 237/250\n",
            "1/1 [==============================] - 1s 618ms/step - loss: 1.3815 - accuracy: 0.3000\n",
            "Epoch 238/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3793 - accuracy: 0.3000\n",
            "Epoch 239/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3866 - accuracy: 0.3000\n",
            "Epoch 240/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3800 - accuracy: 0.3000\n",
            "Epoch 241/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3797 - accuracy: 0.3000\n",
            "Epoch 242/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3697 - accuracy: 0.3000\n",
            "Epoch 243/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3776 - accuracy: 0.3000\n",
            "Epoch 244/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3694 - accuracy: 0.3000\n",
            "Epoch 245/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3680 - accuracy: 0.3000\n",
            "Epoch 246/250\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 1.3822 - accuracy: 0.3000\n",
            "Epoch 247/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3759 - accuracy: 0.3000\n",
            "Epoch 248/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3722 - accuracy: 0.3000\n",
            "Epoch 249/250\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 1.3687 - accuracy: 0.3000\n",
            "Epoch 250/250\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 1.3779 - accuracy: 0.3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXNWrsxlIg-Y",
        "outputId": "ee2ed42f-a31f-4762-981c-8a737bc1bc0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "# Loss: convergence or not: Plot the curve\n",
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh13m5tzn3J1"
      },
      "source": [
        "##### confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_prediction = model.predict(x_train)\n",
        "# Convert predictions classes to one hot vectors\n",
        "y_pred_classes = np.argmax(y_prediction,axis = 1)\n",
        "# Convert validation observations to one hot vectors\n",
        "y_true = np.argmax(y_train,axis = 1)\n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", color = 'g');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "cndOQuOQwyPW",
        "outputId": "dc64e6df-8509-47eb-881b-bfce6341a28f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 41s 41s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDq3v3mrxC4h",
        "outputId": "0b6b424f-33a2-4427-eeab-9e4afb82fef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        }
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_prediction = model.predict(x_test)\n",
        "# Convert predictions classes to one hot vectors\n",
        "y_pred_classes = np.argmax(y_prediction,axis = 1)\n",
        "# Convert validation observations to one hot vectors\n",
        "y_true = np.argmax(y_test,axis = 1)\n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", color = 'g');"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 11s 11s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKsrfVs6tPjb"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pokw6ijmtPgb"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaZqOs7vtPeM"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3wDRIyptPcJ"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT9uF5uatPZZ"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYdTc0MmtPXa"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyrpaT7MtPUx"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgq-0c-KtPSP"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW_YnO7QtPPr"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCF2eS3btPNC"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA2VGUOcGTPg"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    }
  ]
}